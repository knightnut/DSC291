{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods for Homework 2, Team 2\n",
    "## DSC291 - Data Science for Scientists and Engineers\n",
    "\n",
    "This notebook demonstrates how we use aws-jupyter to \n",
    "- automatically start EC2 instances of different types\n",
    "- run the same timed script on all these instances\n",
    "- retrieve the results from all instances\n",
    "- and combine all results with pricing data to compare the performance of different instances\n",
    "\n",
    "While this notebook does not describe our actual experiment (we're submitting another one for that), it is meant as a general desription of how it is possible to use aws-jupyter to run any such experiment. \n",
    "\n",
    "**Run the last cell to turn this notebook into a presentation!**\n",
    "\n",
    "*Note: To successfully run this notebook, it's easiest to start it in the conda environment for packages availability.*\n",
    "\n",
    "    $conda activate\n",
    "$jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "from os.path import isfile,isdir\n",
    "from os import mkdir,chdir,getcwd\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from time import sleep\n",
    "import argparse\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# enable inline graphics\n",
    "%pylab inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We start by listing the instances that are active on our account. \n",
    "This can be helpful, to monitor whether there are any unused instances that are still running, and costing us money.\n",
    "\n",
    "(also, we still haven't been given access to https://ets-apps.ucsd.edu/dsc291-custom-aws/index.cgi, so this is our solution to try to make sure that our costs are not piling up...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!aws ec2 describe-instances \\\n",
    "    --query 'Reservations[*].Instances[*].{Type:InstanceType,\\\n",
    "                                           LaunchTime:LaunchTime,\\\n",
    "                                           Instance:InstanceId,\\\n",
    "                                           KeyName:KeyName,\\\n",
    "                                           State:State.Name,\\\n",
    "                                           Name:Tags[?Key==`cluster-name`]|[0].Value}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Here are a few options for stopping or terminating instances \n",
    "This one is just an example for if one notices any instances that seem to have been running for a while whithout usage. In that case we can uncomment a line and terminate/stop them manually by their instance ID. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's import some data on which instance types are available, and how much they cost.\n",
    "We will use a subset of the instanceType list to start multiple EC2 instances which we want to compare. We will use the pricing data later on, to compare performance to pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pricedf = pd.read_csv('ec2ondemandprices20200419.csv')\n",
    "pricedf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, we are making price column numeric. Then, for this initial test we select only the cheapest instances, to prevent spending too much money on something that might not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "if pricedf['priceHour'].dtype == 'O':\n",
    "    pricedf['priceHour'] = pd.to_numeric(pricedf.priceHour.str.extract('(\\d*\\.?\\d.?\\d.?\\d.)')[0])\n",
    "\n",
    "priceCutOff = 0.5\n",
    "dfTest = pricedf[pricedf['priceHour'] < priceCutOff]\n",
    "\n",
    "typeList = dfTest['instanceType'].tolist()\n",
    "priceList = np.round(dfTest['priceHour'].tolist(),4)\n",
    "print(typeList)\n",
    "print(priceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We'll have to set up each instance before running our test\n",
    "Here, we are creating a script that we will run on each instance to set it up. (This is basically copy-pasted from the class materials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python wrapper for aws-jupyter\n",
    "To use aws-jupyter effectively from a notebook, we are adding some code that makes it easier to run commands from here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A test script to run on each instance\n",
    "\n",
    "Here, we are defining a test script that we will be running on each instance. The calculations to be done are timed a hundred times, and the results are written to a pickle file. \n",
    "\n",
    "For this test, we are just running a quick and simple task (finding the 100,000th Fibonacci number recursively). For our actual experiment, this script is more involved. \n",
    "\n",
    "<font color=red> Add some detail here about what the FileGenerator script is doing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typeL in typeList:\n",
    "    \n",
    "    # Create an instance of typeL\n",
    "    print(\"Creating instance %s\"%typeL)\n",
    "    !aws-jupyter create -c 1 -t $typeL --name $typeL\n",
    "    time.sleep(30) # wait for aws to configure the instance\n",
    "    output = subprocess.Popen(\"aws-jupyter check --name %s\"%typeL, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(\"\\t...done\")\n",
    "    \n",
    "    ## The below directory should be the git repository. the remote directory \"./\" is \"/home/ubuntu/hw2\" on the AWS system\n",
    "    check_file_send = subprocess.Popen('aws-jupyter send-dir --local /home/jakemdaly/Documents/courses/dsc-291/TeamGitRepo/Public-DSC291/hw2/ --remote ./', shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(f\"Sent local directory to instance\")\n",
    "    \n",
    "    # Now we need to find out what the IP address of the cluster is\n",
    "    start_char = str(output).find(\"ubuntu\")\n",
    "    indexer = start_char\n",
    "    while str(output)[indexer] != \" \":\n",
    "        indexer += 1\n",
    "    remote_instance = str(output)[start_char:indexer]\n",
    "    \n",
    "    \n",
    "    # NOTE: Access credentials  were removed from all scripts, so they will not appear down here. You won't be able to run this part of the notebook\n",
    "    print(f\"Remote instance: {remote_instance}\")\n",
    "    print(\"Running the file generator and measuring latencies...\")\n",
    "    check1 = subprocess.Popen(\"ssh -i /home/jakemdaly/.ssh/JakeTeam2KeyPair.pem %s 'pip install s3cmd; cd hw2; /home/ubuntu/.local/bin/s3cmd get s3://jakes-bucket-dsc-291/*.txt . --access_key= --secret_key= --region us-west-2 --force; /usr/bin/python3 TestLatencies.py'\"%remote_instance, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(\"\\t...done\")\n",
    "    print(\"Copying .csv files to local directory and terminating notebook\")\n",
    "    check2 = subprocess.Popen(\"scp -i /home/jakemdaly/.ssh/JakeTeam2KeyPair.pem %s:/home/ubuntu/hw2/latencies.csv /home/jakemdaly/Documents/courses/dsc-291/TeamGitRepo/Public-DSC291/hw2/\"%remote_instance, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    check3 = subprocess.Popen(\"mv latencies.csv latencies_%s.csv\"%(typeL), shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    check4 = subprocess.Popen(\"aws-jupyter terminate --name %s\"%typeL, shell=True).communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all the instances are closed.\n",
    "for typeL in typeList:\n",
    "    subprocess.call(\"aws-jupyter terminate --name %s\"%typeL, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A test script to run on each instance\n",
    "\n",
    "Here, we are defining a test script that we will be running on each instance. The calculations to be done are timed a hundred times, and the results are written to a pickle file. \n",
    "\n",
    "For this test, we are just running a quick and simple task (finding the 100,000th Fibonacci number recursively). For our actual experiment, this script is more involved. \n",
    "\n",
    "<font color=red> Add some detail here about what the FileGenerator script is doing </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we start, let's check which instances we will actually be using.\n",
    "We can also further make the list shorter here, if we are just trying to see if this notebook works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if you want to just try, say, 3 different ones for testing\n",
    "# typeList = typeList[0:3]\n",
    "typeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now lets start all instances in the list and run our timed experiment multiple times!\n",
    "This is where things actually happen. \n",
    "\n",
    "<font color=red> Not sure if we need this code below. Ill uncomment and see if the main chunk runs </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, get all the collected data back into this notebook\n",
    "Here, we create a pandas dataframe with all the data collected from the different types of instances. We need to collect the data from all the different files that were sent back to us from the different instances we've created.\n",
    "\n",
    "We can print the first few lines of the dataframe to see if the data looks about right. \n",
    "\n",
    "*Here, something must have gone wrong on the instance of type **c5.large** that we had created. The output logs (which were deleted because they contained our AWS credentials) seem to indicate that the ssh connection failed when trying to retrieve the file with the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(columns = typeList)\n",
    "# for thisType in typeList:\n",
    "#     filename = 'from_remote/stats_' + thisType.replace('.','-') + '.pkl'\n",
    "#     if isfile(filename):\n",
    "#         infile = open(filename,'rb')\n",
    "#         thisData = pk.load(infile)\n",
    "#         infile.close()\n",
    "#         results[thisType] = thisData\n",
    "\n",
    "# # display the top of the dataframe\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we can finally examine the data!\n",
    "Here, we are just creating a boxplot of the execution times by instance type. We see that the (cheap) instances that we tested all needed on average between 0.12 to 0.24 seconds to determine the 100,00th Fibonacci number recursively. The fastest instance types here are the compute optimized **c5.xlarge** and **c5.2xlarge**, and the memory optimized **r5d.xlarge**. \n",
    "\n",
    "Not surprisingly, these faster instances were also some of the comparatively more expensive ones amongst our set of types. So is it actually worth it paying that higher price to cut the execution time down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# bp1 = results.boxplot(rot=90)\n",
    "# bp1.set_title('execution times on different instance types')\n",
    "# bp1.set_ylabel('execution time in seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cost-effectiveness\n",
    "Here, we multiply the time the computations took by the hourly price of the instance to see how much the computation actually cost us on each type of instance. *(the numbers are very low, since all prices were <$0.50/hr and computation times were less than a second...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# byPrice = pd.DataFrame(columns = typeList)\n",
    "# for i, thisType in enumerate(typeList):\n",
    "#     byPrice[thisType] = priceList[i] * (results[thisType] / 3600)\n",
    "# byPrice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's see how adjusting by price changes our perception of instance performance!\n",
    "Now we see that for the same task, <span style=\"color:red\">the least powerful instance types were actually much more efficient</span> than the more powerful ones in terms of total cost!\n",
    "\n",
    "So, if you have a lot of time and are really just interested in recursively calculating Fibonacci numbers, then you should do so on a **t3.nano** instance! \n",
    "\n",
    "We assume that this price effectiveness will change when you do more complex tasks, such as moving large files between S3 and EC2 instances. This is why the second notebook in our submission for homework 2 is testing this scenario, focussing more on the analysis of the results than on the methods of how to get things running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# bp2 = byPrice.boxplot(rot=90)\n",
    "# bp2.set_title('cost-effectiveness of different instance types')\n",
    "# bp2.set_ylabel('price for execution time of the script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# # To view this notebook as slides\n",
    "# !jupyter nbconvert hw2psa.ipynb --to slides --post serve"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
